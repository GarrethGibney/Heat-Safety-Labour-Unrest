{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f651e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 1. Load FMCS raw data\n",
    "# 2. Clean FMCS datasets\n",
    "# 3. Generate Key Dependent Varialbes\n",
    "# 3. Merge CBP data (number of firms & employees per state per year)\n",
    "# 4. Merge union representation data\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6393d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------- Paths ----------\n",
    "# Define project directory\n",
    "project_dir = Path(\"C:/Users/20234503/Desktop/Research/Strikes, Temperature, and Heat Safety Laws\")\n",
    "# Define raw CSV path\n",
    "raw_csv = project_dir / \"Raw Data\" / \"work_stoppages.csv\"\n",
    "\n",
    "\n",
    "# ---------- Load ----------\n",
    "# Specify encoding/dtypes/dates for deterministic loads across machines.\n",
    "FMCS = pd.read_csv(\n",
    "    raw_csv,\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "\n",
    "# ---------- Clean 'City, State' ----------\n",
    "# Goal: split combined place field into tidy 'City' and 'State' for merges.\n",
    "# 1) normalise trailing punctuation/whitespace (e.g., \"Seattle, WA,\" -> \"Seattle, WA\")\n",
    "FMCS[\"City, State\"] = (\n",
    "    FMCS[\"City, State\"]\n",
    "    .astype(\"string\")\n",
    "    .str.replace(r\",$\", \"\", regex=True)  # drop trailing comma if present\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# 2) split on the LAST comma only (handles cities containing commas upstream, if any)\n",
    "city_state = FMCS[\"City, State\"].str.rsplit(\",\", n=1, expand=True)\n",
    "\n",
    "# 3) assign to new columns with whitespace trimmed\n",
    "FMCS[\"City\"] = city_state[0].str.strip()     # everything before last comma\n",
    "FMCS[\"State\"] = city_state[1].str.strip()    # text after last comma\n",
    "\n",
    "# 4) standardise missing/blank states to NA for consistent filtering/joins\n",
    "FMCS[\"State\"] = (\n",
    "    FMCS[\"State\"]\n",
    "    .astype(\"string\")\n",
    "    .str.strip()\n",
    "    .replace(r\"^\\s*$\", pd.NA, regex=True)\n",
    ")\n",
    "\n",
    "# ---------- Diagnostics (optional but useful for replication logs) ----------\n",
    "# Rows where state is missing after the split (likely malformed 'City, State')\n",
    "bad_rows = FMCS[FMCS[\"State\"].isna()]\n",
    "\n",
    "# If desired in strict pipelines, fail fast when structure isn't as expected:\n",
    "# assert bad_rows.empty, \"Some rows lack a parseable state; inspect 'bad_rows'.\"\n",
    "\n",
    "# Example: inspect a minimal subset when debugging\n",
    "# print(bad_rows[[\"Employer\", \"City, State\"]].head(10))\n",
    "\n",
    "# ---------- Crosswalk: FMCS 'Industry' -> NAICS2 ----------\n",
    "# Assumptions:\n",
    "# - FMCS Industry values map to broad NAICS 2-digit sectors (some as ranges, e.g. \"48-49\").\n",
    "# - Unrecognised/unspecified industries remain NA (documented in logs).\n",
    "# - We standardise text before mapping to reduce mismatches (strip and normalise spaces).\n",
    "\n",
    "# 0) normalise 'Industry' text to reduce key mismatches during mapping\n",
    "FMCS[\"Industry\"] = (\n",
    "    FMCS[\"Industry\"]\n",
    "    .astype(\"string\")\n",
    "    .str.strip()\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)   # collapse multiple spaces\n",
    ")\n",
    "\n",
    "# 1) dictionary crosswalk from FMCS labels to NAICS 2-digit (as strings)\n",
    "crosswalk = {\n",
    "    \"Manufacturing\": \"31-33\",\n",
    "    \"Information\": \"51\",\n",
    "    \"Construction\": \"23\",\n",
    "    \"Health Care and Social Assistance\": \"62\",\n",
    "    \"Educational Services\": \"61\",\n",
    "    \"Transportation and Warehousing\": \"48-49\",\n",
    "    \"Utilities\": \"22\",\n",
    "    \"Retail Trade\": \"44-45\",\n",
    "    \"Wholesale Trade\": \"42\",\n",
    "    \"Real Estate and Rental & Leasing\": \"53\",\n",
    "    \"Professional, Scientific &Tech Serv\": \"54\",\n",
    "    \"Finance and Insurance\": \"52\",\n",
    "    \"Accommodation and Food Services\": \"72\",\n",
    "    \"Arts, Entertainment and Recreation\": \"71\",\n",
    "    \"Mining, Quarrying and Oil & Gas Extraction\": \"21\",\n",
    "    \"Mining and Oil & Gas Extraction\": \"21\",\n",
    "    \"Support Serv. & Waste Management\": \"56\",\n",
    "    \"Personal Serv & Private Organizations\": \"81\",\n",
    "\n",
    "    # Government (aggregate to 92)\n",
    "    \"Federal Government\": \"92\",\n",
    "    \"State Government\": \"92\",\n",
    "    \"Local Government\": \"92\",\n",
    "    \"County Government\": \"92\",\n",
    "    \"Federal, State or Local Government\": \"92\",\n",
    "\n",
    "    # Explicit unknowns\n",
    "    \"Not Specified\": pd.NA,\n",
    "    \"Not Provided\": pd.NA,\n",
    "    \"nan\": pd.NA,\n",
    "}\n",
    "\n",
    "FMCS[\"NAICS2\"] = FMCS[\"Industry\"].map(crosswalk)\n",
    "\n",
    "# Optional diagnostic: count unmapped industries (helps maintain the crosswalk over time)\n",
    "# unmapped = FMCS.loc[FMCS[\"NAICS2\"].isna(), \"Industry\"].value_counts(dropna=False)\n",
    "# print(\"Unmapped industry labels:\\n\", unmapped.head(20))\n",
    "\n",
    "# ---------- Creation of State-Year Panel of Labour Strikes by Indoor & Outdoor Sector ----------\n",
    "# Objectives:\n",
    "# - Generate state-year strike incidence\n",
    "#   (if bargaining power increases, we should observe more unrest).\n",
    "# - Calculate average dispute length\n",
    "#   (captures how long disputes typically take to resolve).\n",
    "# - Classify disputes as short vs. long\n",
    "#   (literature suggests shorter disputes are more likely to be successful;\n",
    "#    cutoff to be defined explicitly — e.g., 7, 14, or 30 days).\n",
    "# - Measure severity of disputes\n",
    "#   (defined as number of workers idle × duration in days; normalisation by state size may be needed).\n",
    "# - Contract content\n",
    "#   (text evidence from collective bargaining agreements; data not yet available).\n",
    "# - Enforcement/pressure channels\n",
    "#   (e.g., OSHA / Cal-OSHA inspections & citations, NLRB unfair labour practice charges; data not yet available).\n",
    "\n",
    "# ---------- Study Period -----------\n",
    "FMCS[\"Start Date\"] = pd.to_datetime(FMCS[\"Start Date\"], errors=\"coerce\") # Convert to datetime (keeps invalids as NaT)\n",
    "FMCS[\"End Date\"]   = pd.to_datetime(FMCS[\"End Date\"], errors=\"coerce\")\n",
    "FMCS[\"Year\"] = FMCS[\"Start Date\"].dt.year # Extract year from Start Date\n",
    "FMCS = FMCS[(FMCS[\"Year\"] >= 2000) & (FMCS[\"Year\"] <= 2010)] # Restrict sample to 2000–2010\n",
    "\n",
    "# ---------- Incidence -----------\n",
    "FMCS = FMCS.reset_index(drop=True)\n",
    "FMCS[\"DisputeID\"] = (\n",
    "    FMCS[\"State\"].astype(str) + \"_\" +\n",
    "    FMCS[\"Year\"].astype(str) + \"_\" +\n",
    "    FMCS.index.astype(str)\n",
    ")\n",
    "# ---------- Duration of Disputes ----------\n",
    "# Duration in days (End - Start)\n",
    "FMCS[\"Dispute_Duration_Days\"] = (FMCS[\"End Date\"] - FMCS[\"Start Date\"]).dt.days\n",
    "FMCS.loc[FMCS[\"Dispute_Duration_Days\"] == 0, \"Dispute_Duration_Days\"] = 1\n",
    "# Clean impossible values\n",
    "FMCS.loc[FMCS[\"Dispute_Duration_Days\"] < 0, \"Dispute_Duration_Days\"] = pd.NA\n",
    "\n",
    "# Short vs. Long Disputes \n",
    "SHORT_CUTOFF = 6\n",
    "FMCS[\"Short_Dispute\"] = np.where(\n",
    "    FMCS[\"Dispute_Duration_Days\"].isna(),\n",
    "    np.nan,\n",
    "    FMCS[\"Dispute_Duration_Days\"].le(SHORT_CUTOFF)\n",
    ")\n",
    "\n",
    "# ---------- Dispute Severity ----------\n",
    "FMCS[\"Severity\"] = FMCS[\"Dispute_Duration_Days\"]*FMCS[\"# Idled\"]\n",
    "\n",
    "# Aggregate to state × NAICS2 × year\n",
    "State_Year_FMCS = (\n",
    "    FMCS.groupby([\"State\", \"NAICS2\", \"Year\"], dropna=False)\n",
    "        .agg(\n",
    "            Count=(\"DisputeID\", \"count\"),           # number of disputes\n",
    "            Avg_Length=(\"Dispute_Duration_Days\", \"mean\"),  # average duration\n",
    "            Severity=(\"Severity\", \"sum\"),           # total idle days × workers\n",
    "            Short_Share=(\"Short_Dispute\", \"mean\")   # proportion short disputes\n",
    "        )\n",
    "        .reset_index()\n",
    ")\n",
    "# ---------- Ensure all state-sector-year combinations are present ----------\n",
    "# This ensures that states/years with no disputes are still represented with zeros.\n",
    "# This is crucial for panel data analysis to avoid bias from missing data.\n",
    "# Create a \"date_year\" timestamp (Jan 1 of each Year)\n",
    "State_Year_FMCS[\"date_year\"] = pd.to_datetime(\n",
    "    State_Year_FMCS[\"Year\"].astype(int).astype(str), format=\"%Y\"\n",
    ")\n",
    "\n",
    "# Build a range covering ALL years in your data (first day of each year)\n",
    "all_years = pd.date_range(\n",
    "    start=f\"{int(State_Year_FMCS['Year'].min())}-01-01\",\n",
    "    end=f\"{int(State_Year_FMCS['Year'].max())}-01-01\",\n",
    "    freq=\"YS\"   # Year Start\n",
    ")\n",
    "\n",
    "# Select relevant columns (adjust based on available columns)\n",
    "state_df  = (State_Year_FMCS[[\"State\"]]\n",
    "             .drop_duplicates()\n",
    "             .dropna()\n",
    "             .sort_values(\"State\")\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "sector_df = (State_Year_FMCS[[\"NAICS2\"]]\n",
    "             .drop_duplicates()\n",
    "             .dropna()\n",
    "             .sort_values(\"NAICS2\")\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "\n",
    "#Merging with temporal data\n",
    "all_combinations = pd.MultiIndex.from_product([state_df['State'], sector_df['NAICS2'], all_years], names=['State', 'NAICS2','date_year']).to_frame(index=False)\n",
    "State_Year_FMCS= pd.merge(State_Year_FMCS, all_combinations, on=['State', 'NAICS2','date_year'], how='right') # how='right' creates a dataset of all counties\n",
    "# Or store as a yearly Period instead of a timestamp\n",
    "State_Year_FMCS[\"Year\"] = State_Year_FMCS[\"date_year\"].dt.year # Extract year from Start Date\n",
    "State_Year_FMCS[\"year_period\"] = pd.PeriodIndex(\n",
    "    State_Year_FMCS[\"Year\"].astype(int), freq=\"Y\"\n",
    ")\n",
    "\n",
    "# ---------- Classify Sector Type: Indoor vs Outdoor ----------\n",
    "# Rule of thumb:\n",
    "# Outdoor-heavy sectors include natural resources, extraction, utilities/field work, construction,\n",
    "# transport/warehousing (field roles), waste mgmt, and government field operations.\n",
    "# NOTE: This is a coarse classification for heat exposure analysis, not a job-level exposure measure.\n",
    "\n",
    "outdoor_naics = {\n",
    "    \"11\",      # Agriculture, forestry, fishing and hunting\n",
    "    \"21\",      # Mining, quarrying, oil & gas extraction\n",
    "    \"22\",      # Utilities (field crews)\n",
    "    \"23\",      # Construction\n",
    "    \"48-49\",   # Transportation and warehousing\n",
    "    \"56\",      # Admin/support & waste management (incl. waste collection)\n",
    "    \"92\",      # Public administration (field services; coarse assumption)\n",
    "}\n",
    "\n",
    "def classify_sector(naics2: pd.Series) -> str | None:\n",
    "    if pd.isna(naics2):\n",
    "        return None\n",
    "    return \"Outdoor\" if naics2 in outdoor_naics else \"Indoor\"\n",
    "\n",
    "State_Year_FMCS[\"Sector_Type\"] = State_Year_FMCS[\"NAICS2\"].apply(classify_sector)\n",
    "\n",
    "State_Year_FMCS[\"outdoor\"] = State_Year_FMCS[\"Sector_Type\"].astype(str).str.lower().eq(\"outdoor\").astype(int)\n",
    "\n",
    "cols = [\"Count\", \"Avg_Length\", \"Severity\", \"Short_Share\"]\n",
    "present = [c for c in cols if c in State_Year_FMCS.columns]\n",
    "State_Year_FMCS[present] = State_Year_FMCS[present].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "# ---------- Merging of Data with CBP and Union Representation Data ----------\n",
    "# State abbreviation to FIPS crosswalk\n",
    "state_to_fips = {\n",
    "    \"AL\": 1,  \"AK\": 2,  \"AZ\": 4,  \"AR\": 5,  \"CA\": 6,\n",
    "    \"CO\": 8,  \"CT\": 9,  \"DE\": 10, \"DC\": 11, \"FL\": 12,\n",
    "    \"GA\": 13, \"HI\": 15, \"ID\": 16, \"IL\": 17, \"IN\": 18,\n",
    "    \"IA\": 19, \"KS\": 20, \"KY\": 21, \"LA\": 22, \"ME\": 23,\n",
    "    \"MD\": 24, \"MA\": 25, \"MI\": 26, \"MN\": 27, \"MS\": 28,\n",
    "    \"MO\": 29, \"MT\": 30, \"NE\": 31, \"NV\": 32, \"NH\": 33,\n",
    "    \"NJ\": 34, \"NM\": 35, \"NY\": 36, \"NC\": 37, \"ND\": 38,\n",
    "    \"OH\": 39, \"OK\": 40, \"OR\": 41, \"PA\": 42, \"RI\": 44,\n",
    "    \"SC\": 45, \"SD\": 46, \"TN\": 47, \"TX\": 48, \"UT\": 49,\n",
    "    \"VT\": 50, \"VA\": 51, \"WA\": 53, \"WV\": 54, \"WI\": 55,\n",
    "    \"WY\": 56,\n",
    "    # Territories\n",
    "    \"PR\": 72, \"VI\": 78,\n",
    "    # Placeholder for missing/unknown\n",
    "    \"Unknown\": None\n",
    "}\n",
    "\n",
    "State_Year_FMCS[\"FIPSSTATE\"] = (\n",
    "    State_Year_FMCS[\"State\"].map(state_to_fips).astype(\"Int64\")\n",
    ")  # nullable integer dtype\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Setup ----------\n",
    "CBP_dir = project_dir / \"Raw Data\" / \"CBP\"\n",
    "\n",
    "all_dfs = []\n",
    "for fp in sorted(CBP_dir.glob(\"Cbp*st.txt\")):\n",
    "    m = re.fullmatch(r\"Cbp(\\d{2})st\\.txt\", fp.name, flags=re.IGNORECASE)\n",
    "    if not m:\n",
    "        continue  # skip unexpected files\n",
    "\n",
    "    year = 2000 + int(m.group(1))\n",
    "\n",
    "    df = pd.read_csv(fp, encoding=\"utf-8\")\n",
    "\n",
    "    # Apply filter\n",
    "    if year == 2010:\n",
    "        mask = (df[\"naics\"] == \"------\") & (df[\"lfo\"] == \"-\")\n",
    "    else:\n",
    "        mask = df[\"naics\"] == \"------\"\n",
    "\n",
    "    df = df.loc[mask, [\"fipstate\", \"emp\", \"est\"]].copy()\n",
    "    df[\"year\"] = year\n",
    "    all_dfs.append(df)\n",
    "\n",
    "# Combine\n",
    "CBP_State_Tot = pd.concat(all_dfs, ignore_index=True)[[\"year\", \"fipstate\", \"emp\", \"est\"]]\n",
    "\n",
    "#Merging CBP_State_Tot with State_Year_FMCS\n",
    "# Standardize CBP column names to match the base df\n",
    "CBP_aligned = (\n",
    "    CBP_State_Tot\n",
    "      .rename(columns={\"fipstate\": \"FIPSSTATE\", \"year\": \"Year\"})  # keys\n",
    "      .rename(columns={\"emp\": \"cbp_emp\", \"est\": \"cbp_est\"})       # payload (optional but recommended)\n",
    "      .copy()\n",
    ")\n",
    "\n",
    "# Make sure dtypes line up\n",
    "State_Year_FMCS[\"FIPSSTATE\"] = State_Year_FMCS[\"FIPSSTATE\"].astype(\"Int64\")\n",
    "State_Year_FMCS[\"Year\"]      = State_Year_FMCS[\"Year\"].astype(\"Int64\")\n",
    "\n",
    "CBP_aligned[\"FIPSSTATE\"] = CBP_aligned[\"FIPSSTATE\"].astype(\"Int64\")\n",
    "CBP_aligned[\"Year\"]      = CBP_aligned[\"Year\"].astype(\"Int64\")\n",
    "\n",
    "# Merge on the matching names\n",
    "State_Year_FMCS_Rate = State_Year_FMCS.merge(\n",
    "    CBP_aligned[[\"FIPSSTATE\", \"Year\", \"cbp_emp\", \"cbp_est\"]],\n",
    "    on=[\"FIPSSTATE\", \"Year\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "#Creating Rates of Dependent Variable\n",
    "State_Year_FMCS_Rate['Count'] = (State_Year_FMCS_Rate['Count']/State_Year_FMCS_Rate['cbp_emp'])*1000000\n",
    "State_Year_FMCS_Rate['Severity'] = (State_Year_FMCS_Rate['Severity']/State_Year_FMCS_Rate['cbp_emp'])*1000000\n",
    "State_Year_FMCS_Rate['Severity'] = (State_Year_FMCS_Rate['Severity']/State_Year_FMCS_Rate['cbp_emp'])*1000000\n",
    "\n",
    "######## Export ######\n",
    "State_Year_FMCS_Rate.to_csv(\"C:\\\\Users\\\\20234503\\\\Desktop\\\\Research\\\\Strikes, Temperature, and Heat Safety Laws\\\\Project\\Data\\\\\"+\"State_Year_FMCS_Rate.csv\", index=False)\n",
    "State_Year_FMCS.to_csv(\"C:\\\\Users\\\\20234503\\\\Desktop\\\\Research\\\\Strikes, Temperature, and Heat Safety Laws\\\\Project\\Data\\\\\"+\"State_Year_FMCS.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f743d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Creation of State-Month Panel of Labour Strikes by Indoor & Outdoor Sector ----------\n",
    "# Objectives:\n",
    "# - Generate state-year strike incidence\n",
    "#   (if bargaining power increases, we should observe more unrest).\n",
    "# - Calculate average dispute length\n",
    "#   (captures how long disputes typically take to resolve).\n",
    "# - Classify disputes as short vs. long\n",
    "#   (literature suggests shorter disputes are more likely to be successful;\n",
    "#    cutoff to be defined explicitly — e.g., 7, 14, or 30 days).\n",
    "# - Measure severity of disputes\n",
    "#   (defined as number of workers idle × duration in days; normalisation by state size may be needed).\n",
    "# - Contract content\n",
    "#   (text evidence from collective bargaining agreements; data not yet available).\n",
    "# - Enforcement/pressure channels\n",
    "#   (e.g., OSHA / Cal-OSHA inspections & citations, NLRB unfair labour practice charges; data not yet available).\n",
    "\n",
    "# ---------- Study Period -----------\n",
    "FMCS[\"Start Date\"] = pd.to_datetime(FMCS[\"Start Date\"], errors=\"coerce\") # Convert to datetime (keeps invalids as NaT)\n",
    "FMCS[\"End Date\"]   = pd.to_datetime(FMCS[\"End Date\"], errors=\"coerce\")\n",
    "FMCS[\"Month\"] = FMCS[\"Start Date\"].dt.month # Extract year from Start Date\n",
    "FMCS[\"Year\"] = FMCS[\"Start Date\"].dt.year # Extract year from Start Date\n",
    "FMCS = FMCS[(FMCS[\"Year\"] >= 2000) & (FMCS[\"Year\"] <= 2010)] # Restrict sample to 2000–2010\n",
    "\n",
    "# ---------- Incidence -----------\n",
    "FMCS = FMCS.reset_index(drop=True)\n",
    "FMCS[\"DisputeID\"] = (\n",
    "    FMCS[\"State\"].astype(str) + \"_\" +\n",
    "    FMCS[\"Year\"].astype(str) + \"_\" +\n",
    "    FMCS.index.astype(str)\n",
    ")\n",
    "# ---------- Duration of Disputes ----------\n",
    "# Duration in days (End - Start)\n",
    "FMCS[\"Dispute_Duration_Days\"] = (FMCS[\"End Date\"] - FMCS[\"Start Date\"]).dt.days\n",
    "FMCS.loc[FMCS[\"Dispute_Duration_Days\"] == 0, \"Dispute_Duration_Days\"] = 1\n",
    "# Clean impossible values\n",
    "FMCS.loc[FMCS[\"Dispute_Duration_Days\"] < 0, \"Dispute_Duration_Days\"] = pd.NA\n",
    "\n",
    "# Short vs. Long Disputes \n",
    "SHORT_CUTOFF = 6\n",
    "FMCS[\"Short_Dispute\"] = np.where(\n",
    "    FMCS[\"Dispute_Duration_Days\"].isna(),\n",
    "    np.nan,\n",
    "    FMCS[\"Dispute_Duration_Days\"].le(SHORT_CUTOFF)\n",
    ")\n",
    "\n",
    "# ---------- Dispute Severity ----------\n",
    "FMCS[\"Severity\"] = FMCS[\"Dispute_Duration_Days\"]*FMCS[\"# Idled\"]\n",
    "\n",
    "# Aggregate to state × NAICS2 × year\n",
    "State_Month_FMCS = (\n",
    "    FMCS.groupby([\"State\", \"NAICS2\", \"Month\", \"Year\"], dropna=False)\n",
    "        .agg(\n",
    "            Count=(\"DisputeID\", \"count\"),           # number of disputes\n",
    "            Avg_Length=(\"Dispute_Duration_Days\", \"mean\"),  # average duration\n",
    "            Severity=(\"Severity\", \"sum\"),           # total idle days × workers\n",
    "            Short_Share=(\"Short_Dispute\", \"mean\")   # proportion short disputes\n",
    "        )\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "# ---------- Ensure all state-sector-year combinations are present ----------\n",
    "# This ensures that states/years with no disputes are still represented with zeros.\n",
    "# This is crucial for panel data analysis to avoid bias from missing data.\n",
    "# Create a \"date_year\" timestamp (Jan 1 of each Year)\n",
    "State_Month_FMCS['date_month'] = pd.to_datetime(\n",
    "    State_Month_FMCS['Year'].astype(str) + '-' + State_Month_FMCS['Month'].astype(str) + '-01'\n",
    ")\n",
    "\n",
    "# Build a range covering ALL years in your data (first day of each year)\n",
    "all_months = pd.date_range(\n",
    "    start=State_Month_FMCS['date_month'].min(),\n",
    "    end=State_Month_FMCS['date_month'].max(),\n",
    "    freq='MS'  # Month Start\n",
    ")\n",
    "\n",
    "# Select relevant columns (adjust based on available columns)\n",
    "state_df  = (State_Month_FMCS[[\"State\"]]\n",
    "             .drop_duplicates()\n",
    "             .dropna()\n",
    "             .sort_values(\"State\")\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "sector_df = (State_Month_FMCS[[\"NAICS2\"]]\n",
    "             .drop_duplicates()\n",
    "             .dropna()\n",
    "             .sort_values(\"NAICS2\")\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "\n",
    "#Merging with temporal data\n",
    "all_combinations = pd.MultiIndex.from_product([state_df['State'], sector_df['NAICS2'], all_months], names=['State', 'NAICS2','date_month']).to_frame(index=False)\n",
    "State_Month_FMCS= pd.merge(State_Month_FMCS, all_combinations, on=['State', 'NAICS2','date_month'], how='right') # how='right' creates a dataset of all counties\n",
    "\n",
    "State_Month_FMCS[\"Year\"] = State_Month_FMCS[\"date_month\"].dt.year # Extract year from Start Date\n",
    "State_Month_FMCS[\"Month\"] = State_Month_FMCS[\"date_month\"].dt.month # Extract year from Start Date\n",
    "# ---------- Classify Sector Type: Indoor vs Outdoor ----------\n",
    "# Rule of thumb:\n",
    "# Outdoor-heavy sectors include natural resources, extraction, utilities/field work, construction,\n",
    "# transport/warehousing (field roles), waste mgmt, and government field operations.\n",
    "# NOTE: This is a coarse classification for heat exposure analysis, not a job-level exposure measure.\n",
    "\n",
    "outdoor_naics = {\n",
    "    \"11\",      # Agriculture, forestry, fishing and hunting\n",
    "    \"21\",      # Mining, quarrying, oil & gas extraction\n",
    "    \"22\",      # Utilities (field crews)\n",
    "    \"23\",      # Construction\n",
    "    \"48-49\",   # Transportation and warehousing\n",
    "    \"56\",      # Admin/support & waste management (incl. waste collection)\n",
    "    \"92\",      # Public administration (field services; coarse assumption)\n",
    "}\n",
    "\n",
    "def classify_sector(naics2: pd.Series) -> str | None:\n",
    "    if pd.isna(naics2):\n",
    "        return None\n",
    "    return \"Outdoor\" if naics2 in outdoor_naics else \"Indoor\"\n",
    "\n",
    "State_Month_FMCS[\"Sector_Type\"] = State_Month_FMCS[\"NAICS2\"].apply(classify_sector)\n",
    "\n",
    "State_Month_FMCS[\"outdoor\"] = State_Month_FMCS[\"Sector_Type\"].astype(str).str.lower().eq(\"outdoor\").astype(int)\n",
    "\n",
    "cols = [\"Count\", \"Avg_Length\", \"Severity\", \"Short_Share\"]\n",
    "present = [c for c in cols if c in State_Year_FMCS.columns]\n",
    "State_Month_FMCS[present] = State_Month_FMCS[present].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "# ---------- Merging of Data with CBP and Union Representation Data ----------\n",
    "# State abbreviation to FIPS crosswalk\n",
    "state_to_fips = {\n",
    "    \"AL\": 1,  \"AK\": 2,  \"AZ\": 4,  \"AR\": 5,  \"CA\": 6,\n",
    "    \"CO\": 8,  \"CT\": 9,  \"DE\": 10, \"DC\": 11, \"FL\": 12,\n",
    "    \"GA\": 13, \"HI\": 15, \"ID\": 16, \"IL\": 17, \"IN\": 18,\n",
    "    \"IA\": 19, \"KS\": 20, \"KY\": 21, \"LA\": 22, \"ME\": 23,\n",
    "    \"MD\": 24, \"MA\": 25, \"MI\": 26, \"MN\": 27, \"MS\": 28,\n",
    "    \"MO\": 29, \"MT\": 30, \"NE\": 31, \"NV\": 32, \"NH\": 33,\n",
    "    \"NJ\": 34, \"NM\": 35, \"NY\": 36, \"NC\": 37, \"ND\": 38,\n",
    "    \"OH\": 39, \"OK\": 40, \"OR\": 41, \"PA\": 42, \"RI\": 44,\n",
    "    \"SC\": 45, \"SD\": 46, \"TN\": 47, \"TX\": 48, \"UT\": 49,\n",
    "    \"VT\": 50, \"VA\": 51, \"WA\": 53, \"WV\": 54, \"WI\": 55,\n",
    "    \"WY\": 56,\n",
    "    # Territories\n",
    "    \"PR\": 72, \"VI\": 78,\n",
    "    # Placeholder for missing/unknown\n",
    "    \"Unknown\": None\n",
    "}\n",
    "\n",
    "State_Month_FMCS[\"FIPSSTATE\"] = (\n",
    "    State_Month_FMCS[\"State\"].map(state_to_fips).astype(\"Int64\")\n",
    ")  # nullable integer dtype\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Setup ----------\n",
    "CBP_dir = project_dir / \"Raw Data\" / \"CBP\"\n",
    "\n",
    "all_dfs = []\n",
    "for fp in sorted(CBP_dir.glob(\"Cbp*st.txt\")):\n",
    "    m = re.fullmatch(r\"Cbp(\\d{2})st\\.txt\", fp.name, flags=re.IGNORECASE)\n",
    "    if not m:\n",
    "        continue  # skip unexpected files\n",
    "\n",
    "    year = 2000 + int(m.group(1))\n",
    "\n",
    "    df = pd.read_csv(fp, encoding=\"utf-8\")\n",
    "\n",
    "    # Apply filter\n",
    "    if year == 2010:\n",
    "        mask = (df[\"naics\"] == \"------\") & (df[\"lfo\"] == \"-\")\n",
    "    else:\n",
    "        mask = df[\"naics\"] == \"------\"\n",
    "\n",
    "    df = df.loc[mask, [\"fipstate\", \"emp\", \"est\"]].copy()\n",
    "    df[\"year\"] = year\n",
    "    all_dfs.append(df)\n",
    "\n",
    "# Combine\n",
    "CBP_State_Tot = pd.concat(all_dfs, ignore_index=True)[[\"year\", \"fipstate\", \"emp\", \"est\"]]\n",
    "\n",
    "#Merging CBP_State_Tot with State_Year_FMCS\n",
    "# Standardize CBP column names to match the base df\n",
    "CBP_aligned = (\n",
    "    CBP_State_Tot\n",
    "      .rename(columns={\"fipstate\": \"FIPSSTATE\", \"year\": \"Year\"})  # keys\n",
    "      .rename(columns={\"emp\": \"cbp_emp\", \"est\": \"cbp_est\"})       # payload (optional but recommended)\n",
    "      .copy()\n",
    ")\n",
    "\n",
    "# Make sure dtypes line up\n",
    "State_Month_FMCS[\"FIPSSTATE\"] = State_Month_FMCS[\"FIPSSTATE\"].astype(\"Int64\")\n",
    "State_Month_FMCS[\"Year\"]      = State_Month_FMCS[\"Year\"].astype(\"Int64\")\n",
    "\n",
    "CBP_aligned[\"FIPSSTATE\"] = CBP_aligned[\"FIPSSTATE\"].astype(\"Int64\")\n",
    "CBP_aligned[\"Year\"]      = CBP_aligned[\"Year\"].astype(\"Int64\")\n",
    "\n",
    "# Merge on the matching names\n",
    "State_Month_FMCS_Rate = State_Month_FMCS.merge(\n",
    "    CBP_aligned[[\"FIPSSTATE\", \"Year\", \"cbp_emp\", \"cbp_est\"]],\n",
    "    on=[\"FIPSSTATE\", \"Year\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "#Creating Rates of Dependent Variable\n",
    "State_Month_FMCS_Rate['Count'] = (State_Month_FMCS_Rate['Count']/State_Month_FMCS_Rate['cbp_emp'])*1000000\n",
    "State_Month_FMCS_Rate['Severity'] = (State_Month_FMCS_Rate['Severity']/State_Month_FMCS_Rate['cbp_emp'])*1000000\n",
    "State_Month_FMCS_Rate['Severity'] = (State_Month_FMCS_Rate['Severity']/State_Month_FMCS_Rate['cbp_emp'])*1000000\n",
    "\n",
    "######## Export ######\n",
    "State_Month_FMCS_Rate.to_csv(\"C:\\\\Users\\\\20234503\\\\Desktop\\\\Research\\\\Strikes, Temperature, and Heat Safety Laws\\\\Project\\Data\\\\\"+\"State_Month_FMCS_Rate.csv\", index=False)\n",
    "State_Month_FMCS.to_csv(\"C:\\\\Users\\\\20234503\\\\Desktop\\\\Research\\\\Strikes, Temperature, and Heat Safety Laws\\\\Project\\Data\\\\\"+\"State_Month_FMCS.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
